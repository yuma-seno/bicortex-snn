# Bi-Cortex SNN (BC-SNN) Technical Specification

**Project Name:** Bi-Cortex SNN
**Date:** 2026-01-13
**Target Platform:** Edge Devices (Microcontrollers, FPGA, Mobile)

---

## 1. コンセプト (Concept)

本モデルは、**「不変の知能（Thinking Cortex）」**と**「流動的な記憶（Memory Cortex）」**を単一のニューロン群の中に共存させた、エッジデバイス向けの軽量・リアルタイムSNNモデルである。

### コア・フィロソフィー
1.  **単一ネットワーク・異種機能:** 物理的な層（Layer）構造を持たず、ニューロンIDによる領域区分（Parcellation）のみで「推論」と「記憶」の役割を分担する。
2.  **意味的共鳴 (Semantic Resonance):** バックプロパゲーションを用いず、思考野が「意味」を検知した瞬間のみ局所的な可塑性を活性化させることで、超低コストな学習を実現する。
3.  **時間的因果性の克服:** リカレント構造と長時間トレース変数を組み合わせ、数秒〜数十秒のタイムラグがある事象間の因果関係を学習する。

---

## 2. ニューロン・アーキテクチャ (Architecture)

### 2.1 領域定義 (Parcellation)

| 領域名 | ID範囲 | 役割 | パラメータ特性 |
| :--- | :--- | :--- | :--- |
| **思考野 (Thinking Cortex / TC)** | $0 \dots N_{th}-1$ | 特徴抽出、概念認識、反射的行動 | **固定 (Fixed)** |
| **記憶野 (Memory Cortex / MC)** | $N_{th} \dots N_{total}-1$ | 文脈保持、連想学習 | **内部可塑 / 出力固定** |

# ... (中略)

### 2.3 記憶野 (MC) の構成
* **構造:** 相互結合されたリカレント回路。
* **連想記憶 (Associative Memory):** 内部の結合荷重を動的に変化させることで、異なる文脈間の因果関係を学習する。
* **安定化:** **順応 (Adaptation)** により、強力なループ形成時でも発火を自然に鎮静化させる。

---

## 3. 結合トポロジーと情報の流れ (Connectivity & Flow)

### 3.1 固定結合 (Fixed Connections)
* **Input $\to$ Hidden $\to$ Motor:** 反射行動。
* **TC $\to$ MC (Context Injection):** 文脈注入。
* **MC $\to$ TC (Interface):** 記憶からの読み出し（Readout）。**本モデルではここは固定される。**

### 3.2 可塑的結合 (Plastic Connections) - 連想記憶
**意味的共鳴ゲーティング**によってリアルタイムに重みが更新される。
* **$MC \to MC$ (Recurrent):**
    * 過去の記憶（Pre）と現在の記憶（Post）を結びつける。
    * 例：ベルの記憶（過去）が、エサの記憶（現在）と結びつき、ベルだけでエサの記憶が想起されるようになる。

---

## 4. ダイナミクスと数式 (Dynamics & Math)

### 4.1 ニューロンモデル (Adaptive LIF)
LIFモデルに**適応的閾値 (Adaptive Threshold)** を導入し、恒常性（Homeostasis）を維持する。

$$v_i(t) = v_i(t-1) \cdot \alpha + I_{input}(t) + \sum_{j} w_{ij} S_j(t-1)$$
$$v_{th}(t) = v_{base} + v_{adaptive}(t)$$

* **順応 (Adaptation):** 発火するたびに閾値オフセット $v_{adaptive}$ を上昇させ、ニューロンを「疲れ」させる。
* **回復:** 時間経過とともに $v_{adaptive}$ は 0 に減衰する。

---

## 5. 学習アルゴリズム: 3-Factor Learning (SRG + RL)

### 5.1 ゲート信号 $G(t)$
思考野の活動量の**移動平均 (Moving Average)** が、一定の割合を超えた場合にゲートを開く。
$$G(t) = 1 \quad \text{if} \quad Activity_{MA}(t) \ge \theta_{ratio} \cdot N_{TC} \quad \text{else} \quad 0$$

### 5.2 重み更新則 (Soft-bound)
重みの飽和と反転（Dale's Law違反）を防ぐため、現在の重み値に応じた更新を行う。更新量は **Hebbian項** と **報酬項** の和となる。

$$\Delta w_{ij}(t) = (W_{limit} - w_{ij}) \cdot (\Delta w_{Hebb} + \Delta w_{RL})$$

* **Hebbian項:** ゲート開放時の因果関係強化。
* **報酬項:** 外部報酬 $R(t)$ による強化・抑制。
    * 正の報酬：予期成功時などに付与。
    * 負の報酬：False Alarm（誤発火）時などに付与。

---

## 6. 開発ロードマップ (Development Roadmap)

### Phase 1: コアロジック検証 (Proof of Concept)
Python/NumPyによる最小構成シミュレーション。
* **目的:** 基本原理（SRG, Dual Traces, Interface Learning）が機能するかの確認。
* **構成:**
    * TC: ダミーのルールベース入力（ベル入力、エサ入力）。
    * MC: 50~100ニューロンのLSM。
* **タスク:** 古典的条件付け（パブロフの犬）。ベル（予兆）からエサ（報酬）までの時間差を学習し、ベルだけで反応できるか検証。
* **Output:** `bicortex_poc_v1.py`

### Phase 2: 視覚エンコーディング統合
画像入力を扱えるようにし、空間認識能力を付与する。
* **目的:** 実践的な入力データ（画像）の処理。
* **構成:**
    * TC: **MobileNetV3 (Small)** などの軽量CNNをバックボーンに使用。その特徴マップをSNN電流に変換して入力。
    * MC: 200~500ニューロン規模へ拡張。
* **タスク:** 2Dグリッドワールドにおける、動的な障害物回避。
* **Output:** `bicortex_visual_nav.py`

### Phase 3: リアルタイム・アクション適応
動的に変化する環境での適応能力と堅牢性の検証。
* **目的:** ゲーム等の複雑な環境での実用性確認。
* **構成:** Phase 2のモデルを強化し、OpenAI Gym (Atari) や自作ゲーム環境に接続。
* **シナリオ:**
    * 「特定の色の背景の時だけ、敵の行動パターンが変わる」といった、文脈依存のルール変化に適応できるかテストする。
* **Output:** `bicortex_action_learner.py`

### Phase 4: [Experimental] Spiking LLM 統合実験
**本モデルの拡張可能性を探るための実験的フェーズ。**
* **目的:** 思考野(TC)のバックボーンを、CNNから**Spiking LLM (RWKV/Spikformer等)** に置き換えてみる。
* **仮説:** 言語モデルが持つ高度な世界解釈能力を「概念ニューロン」として利用することで、自然言語による指示や、複雑な論理的文脈を記憶野に保持させることが可能になるのではないか。
* **アプローチ:**
    * 小規模なSpiking LLM (例: RWKV-100M程度) をTC領域に配置。
    * 言語入力に対するLLMの内部発火パターンをMCへ流し込み、「言葉の意味」と「行動」の連想記憶を試みる。
* **Output:** `bicortex_spiking_llm_test.py`

---