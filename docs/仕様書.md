# Bi-Cortex SNN (BC-SNN) Technical Specification

**Project Name:** Bi-Cortex SNN
**Date:** 2026-01-13
**Target Platform:** Edge Devices (Microcontrollers, FPGA, Mobile)

---

## 1. コンセプト (Concept)

本モデルは、**「不変の知能（Thinking Cortex）」**と**「流動的な記憶（Memory Cortex）」**を単一のニューロン群の中に共存させた、エッジデバイス向けの軽量・リアルタイムSNNモデルである。

### コア・フィロソフィー
1.  **単一ネットワーク・異種機能:** 物理的な層（Layer）構造を持たず、ニューロンIDによる領域区分（Parcellation）のみで「推論」と「記憶」の役割を分担する。
2.  **意味的共鳴 (Semantic Resonance):** バックプロパゲーションを用いず、思考野が「意味」を検知した瞬間のみ局所的な可塑性を活性化させることで、超低コストな学習を実現する。
3.  **時間的因果性の克服:** リカレント構造と長時間トレース変数を組み合わせ、数秒〜数十秒のタイムラグがある事象間の因果関係を学習する。

---

## 2. ニューロン・アーキテクチャ (Architecture)

全ニューロン数 $N_{total}$ のフラットな配列を定義し、ID範囲によって機能領域を区分する。

### 2.1 領域定義 (Parcellation)

| 領域名 | ID範囲 | 役割 | パラメータ特性 |
| :--- | :--- | :--- | :--- |
| **思考野 (Thinking Cortex / TC)** | $0 \dots N_{th}-1$ | 特徴抽出、概念認識、反射的行動 | **固定 (Fixed)** |
| **記憶野 (Memory Cortex / MC)** | $N_{th} \dots N_{total}-1$ | 文脈保持、時系列パターンの統合 | **動的 (Plastic)** |

### 2.2 思考野 (TC) の内部構造
TCは、事前にタスクに応じた教師あり学習（CNNや単純なSNN等）が行われており、以下のサブセットを持つ。

1.  **感覚ニューロン (Sensory):** 外部センサー（視覚・聴覚など）の入力を受け取る。
2.  **概念ニューロン (Concept):** 入力から抽出された特徴（例：「敵」「壁」「特定の音」）に反応する。**※SRG（学習ゲート）の監視対象。**
3.  **運動ニューロン (Motor):** システムの最終的なアクション信号を出力する。

### 2.3 記憶野 (MC) の構成
* **リザーバ構造:** ニューロン同士がランダムかつスパース（接続率10-20%程度）に相互結合されたリカレント回路。
* **E/Iバランス (Dale's Law):**
    * 興奮性 (Excitatory): 80%
    * 抑制性 (Inhibitory): 20%
    * ※抑制性ニューロンの導入により、記憶活動の爆発を防ぎ「カオスの縁 (Edge of Chaos)」状態を維持する。

---

## 3. 結合トポロジーと情報の流れ (Connectivity & Flow)

### 3.1 固定結合 (Fixed Connections) - 事前知識
初期化時に設定され、推論中は変化しない。
* **$TC \to TC$:** 事前学習済みの重み。入力から概念を抽出し、基本行動（反射）を生成する。
* **$TC_{concept} \to MC$ (Context Injection):** 思考野で認識された「現在の概念」を記憶野全体へブロードキャストする。これにより記憶野は「今、何が起きているか」というコンテキストを受け取る。

### 3.2 可塑的結合 (Plastic Connections) - 短期記憶
**意味的共鳴ゲーティング**によってリアルタイムに重みが更新される。
* **$MC \to MC$ (Recurrent):** 入力されたコンテキストを時間的に保持・変形し、短期記憶（残響）を形成する。
* **$MC \to TC_{motor}$ (Interface Synapses):** **最重要結合。**
    * 記憶野の特定のパターン（過去の残響）を、思考野の運動ニューロンに直結させる。
    * これにより、「今の視覚情報」だけでなく、「さっきの出来事」に基づいて行動を変化させる（連想記憶）。

---

## 4. ダイナミクスと数式 (Dynamics & Math)

### 4.1 ニューロンモデル (LIF)
計算効率を最優先し、Leaky Integrate-and-Fire モデルを採用。

$$v_i(t) = v_i(t-1) \cdot \alpha_{decay} + I_{input}(t) + \sum_{j} w_{ij} S_j(t-1)$$

* 発火条件: $v_i \ge v_{th}$ ならば $S_i(t)=1, v_i(t)=0$

### 4.2 2つのトレース変数 (Dual Traces)
「土管を見て(原因) $\to$ 数秒後 $\to$ 敵が出る(結果)」といった時間差学習を解決するための機構。

1.  **即時トレース ($x_{fast}$):** $\tau_{fast} \approx 20ms$。通常のシナプス伝達用。
2.  **適格性トレース ($e_{slow}$):** $\tau_{slow} \approx 2.0s \sim 5.0s$。
    $$e_{slow, i}(t) = e_{slow, i}(t-1) \cdot (1 - \frac{1}{\tau_{slow}}) + S_i(t)$$
    * ニューロンが発火すると、そのニューロンには長時間「タグ（発火履歴）」が残る。これにより、未来の報酬信号が到達した際、過去の原因ニューロンを特定できる。

---

## 5. 学習アルゴリズム: 意味的共鳴ゲーティング (SRG)

### 5.1 ゲート信号 $G(t)$
思考野の**概念ニューロン群 ($C$)** の活動総量を監視し、学習の許可証を発行する。

$$G(t) = \text{step\_function} \left( \sum_{k \in TC_{concept}} S_k(t) - \theta_{gate} \right)$$

* **ロジック:** 思考野が「意味のあるもの（敵、アイテム、予兆）」を認識した瞬間のみ $G(t)=1$ となり、回路の書き換え（記憶）が許可される。ノイズ入力時は $G(t)=0$ であり、無駄な記憶容量を消費しない。

### 5.2 インターフェース結合の更新則
「予知行動」を形成するための学習則。

$$\Delta w_{mj}(t) = \eta \cdot G(t) \cdot S_{motor, j}(t) \cdot e_{slow, m}(t)$$

* $m \in MC$ (Presynaptic / 記憶野)
* $j \in TC_{motor}$ (Postsynaptic / 思考野運動)
* **解釈:**
    * **$G(t)$:** 「今、重要な局面である」
    * **$S_{motor, j}(t)$:** 「思考野が（反射的に）この行動をとった」
    * **$e_{slow, m}(t)$:** 「数秒前に記憶野のこのニューロンが活動していた（原因候補）」
    * **結論:** これらを掛け合わせることで、「あの予兆($m$)があったから、この行動($j$)が必要だった」というルールを即座に形成する。

---

## 6. 開発ロードマップ (Development Roadmap)

### Phase 1: コアロジック検証 (Proof of Concept)
Python/NumPyによる最小構成シミュレーション。
* **目的:** 基本原理（SRG, Dual Traces, Interface Learning）が機能するかの確認。
* **構成:**
    * TC: ダミーのルールベース入力（ベル入力、エサ入力）。
    * MC: 50~100ニューロンのLSM。
* **タスク:** 古典的条件付け（パブロフの犬）。ベル（予兆）からエサ（報酬）までの時間差を学習し、ベルだけで反応できるか検証。
* **Output:** `bicortex_poc_v1.py`

### Phase 2: 視覚エンコーディング統合
画像入力を扱えるようにし、空間認識能力を付与する。
* **目的:** 実践的な入力データ（画像）の処理。
* **構成:**
    * TC: **MobileNetV3 (Small)** などの軽量CNNをバックボーンに使用。その特徴マップをSNN電流に変換して入力。
    * MC: 200~500ニューロン規模へ拡張。
* **タスク:** 2Dグリッドワールドにおける、動的な障害物回避。
* **Output:** `bicortex_visual_nav.py`

### Phase 3: リアルタイム・アクション適応
動的に変化する環境での適応能力と堅牢性の検証。
* **目的:** ゲーム等の複雑な環境での実用性確認。
* **構成:** Phase 2のモデルを強化し、OpenAI Gym (Atari) や自作ゲーム環境に接続。
* **シナリオ:**
    * 「特定の色の背景の時だけ、敵の行動パターンが変わる」といった、文脈依存のルール変化に適応できるかテストする。
* **Output:** `bicortex_action_learner.py`

### Phase 4: [Experimental] Spiking LLM 統合実験
**本モデルの拡張可能性を探るための実験的フェーズ。**
* **目的:** 思考野(TC)のバックボーンを、CNNから**Spiking LLM (RWKV/Spikformer等)** に置き換えてみる。
* **仮説:** 言語モデルが持つ高度な世界解釈能力を「概念ニューロン」として利用することで、自然言語による指示や、複雑な論理的文脈を記憶野に保持させることが可能になるのではないか。
* **アプローチ:**
    * 小規模なSpiking LLM (例: RWKV-100M程度) をTC領域に配置。
    * 言語入力に対するLLMの内部発火パターンをMCへ流し込み、「言葉の意味」と「行動」の連想記憶を試みる。
* **Output:** `bicortex_spiking_llm_test.py`

---